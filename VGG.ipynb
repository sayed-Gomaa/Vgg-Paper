{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T14:08:56.410656Z","iopub.execute_input":"2021-11-01T14:08:56.410976Z","iopub.status.idle":"2021-11-01T14:09:25.569979Z","shell.execute_reply.started":"2021-11-01T14:08:56.410893Z","shell.execute_reply":"2021-11-01T14:09:25.569115Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print(dirname)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:25.571796Z","iopub.execute_input":"2021-11-01T14:09:25.572045Z","iopub.status.idle":"2021-11-01T14:09:25.578068Z","shell.execute_reply.started":"2021-11-01T14:09:25.572010Z","shell.execute_reply":"2021-11-01T14:09:25.577197Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nimport os\nimport shutil\nimport glob","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:25.579636Z","iopub.execute_input":"2021-11-01T14:09:25.580544Z","iopub.status.idle":"2021-11-01T14:09:29.890225Z","shell.execute_reply.started":"2021-11-01T14:09:25.580505Z","shell.execute_reply":"2021-11-01T14:09:29.889479Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\ndef plot_imgs(item_dir, top=10):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][100:106]\n  \n    plt.figure(figsize=(10, 10))\n  \n    for idx, img_path in enumerate(item_files):\n        plt.subplot(1, 6, idx+1)        \n        img = plt.imread(img_path)\n        plt.tight_layout() \n        plt.axis('off')\n        plt.imshow(img, cmap='gray')\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:29.892844Z","iopub.execute_input":"2021-11-01T14:09:29.893327Z","iopub.status.idle":"2021-11-01T14:09:29.899910Z","shell.execute_reply.started":"2021-11-01T14:09:29.893281Z","shell.execute_reply":"2021-11-01T14:09:29.899117Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"training_data_path=\"/kaggle/input/intel-image-classification/seg_train/seg_train\"\ntesting_data_path=\"/kaggle/input/intel-image-classification/seg_test/seg_test\"","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:29.901284Z","iopub.execute_input":"2021-11-01T14:09:29.901544Z","iopub.status.idle":"2021-11-01T14:09:29.911259Z","shell.execute_reply.started":"2021-11-01T14:09:29.901511Z","shell.execute_reply":"2021-11-01T14:09:29.910355Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img_height = 224\nimg_width = 224\n\ntraining_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40,\n                                                                    shear_range=0.2,\n                                                                    zoom_range=0.2,\n                                                                    horizontal_flip=True,\n                                                                    vertical_flip=True,\n                                                                    rescale=1/255.0,\n                                                                    validation_split=0.25)\n\ntrain_generator = training_data_gen.flow_from_directory(training_data_path,\n                                                        target_size=(img_height, img_width),\n                                                        batch_size=10,\n                                                        shuffle=True,\n                                                        class_mode='categorical',\n                                                        subset='training') # set as training data\n\nvalidation_generator = training_data_gen.flow_from_directory(training_data_path, # same directory as training data\n                                                             target_size=(img_height, img_width),\n                                                             batch_size=10,\n                                                             shuffle=True,\n                                                             class_mode='categorical',\n                                                             subset='validation') # set as validation data\n \n\ntesting_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n\ntest_generator = testing_data_gen.flow_from_directory(testing_data_path,\n                                                      target_size=(img_height, img_width),\n                                                      batch_size=10,\n                                                      seed=0,\n                                                      shuffle=False,\n                                                      class_mode='categorical') ","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:29.912688Z","iopub.execute_input":"2021-11-01T14:09:29.912961Z","iopub.status.idle":"2021-11-01T14:09:33.838616Z","shell.execute_reply.started":"2021-11-01T14:09:29.912923Z","shell.execute_reply":"2021-11-01T14:09:33.837830Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":" img,lebel=next(train_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:33.839973Z","iopub.execute_input":"2021-11-01T14:09:33.840406Z","iopub.status.idle":"2021-11-01T14:09:34.068728Z","shell.execute_reply.started":"2021-11-01T14:09:33.840364Z","shell.execute_reply":"2021-11-01T14:09:34.067888Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(2, 4, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:34.071482Z","iopub.execute_input":"2021-11-01T14:09:34.072058Z","iopub.status.idle":"2021-11-01T14:09:34.081545Z","shell.execute_reply.started":"2021-11-01T14:09:34.072012Z","shell.execute_reply":"2021-11-01T14:09:34.080718Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plotImages(img)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:34.083180Z","iopub.execute_input":"2021-11-01T14:09:34.083462Z","iopub.status.idle":"2021-11-01T14:09:35.778694Z","shell.execute_reply.started":"2021-11-01T14:09:34.083418Z","shell.execute_reply":"2021-11-01T14:09:35.777916Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_11=tf.keras.models.Sequential()\n\n#_____________________________________ Block 1 __________________________________________#\nmodel_11.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=4,activation='relu',padding='same',input_shape=(224,224,3)))\nmodel_11.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 2 __________________________________________#\nmodel_11.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_11.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n#_____________________________________ Block 3 __________________________________________#\nmodel_11.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 4 __________________________________________#\nmodel_11.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 5 __________________________________________#\nmodel_11.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_11.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n\n\nmodel_11.add(tf.keras.layers.Flatten())\n\n#______________________________Dense Layers_______________________________________________#\nmodel_11.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_11.add(tf.keras.layers.Dropout(.5))\nmodel_11.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_11.add(tf.keras.layers.Dropout(.5))\n\n#______________________________Output Layer _______________________________________________#\nmodel_11.add(tf.keras.layers.Dense(units=6,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:35.781425Z","iopub.execute_input":"2021-11-01T14:09:35.781733Z","iopub.status.idle":"2021-11-01T14:09:38.256859Z","shell.execute_reply.started":"2021-11-01T14:09:35.781687Z","shell.execute_reply":"2021-11-01T14:09:38.255066Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_11.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:38.258196Z","iopub.execute_input":"2021-11-01T14:09:38.258445Z","iopub.status.idle":"2021-11-01T14:09:38.275637Z","shell.execute_reply.started":"2021-11-01T14:09:38.258411Z","shell.execute_reply":"2021-11-01T14:09:38.274944Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_11.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory_11=model_11.fit(train_generator,validation_data=validation_generator, epochs=20,verbose=1)\nmodel_11.save('model_11.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T14:09:38.277043Z","iopub.execute_input":"2021-11-01T14:09:38.277326Z","iopub.status.idle":"2021-11-01T15:04:26.889210Z","shell.execute_reply.started":"2021-11-01T14:09:38.277291Z","shell.execute_reply":"2021-11-01T15:04:26.888394Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_13=tf.keras.models.Sequential()\n\n#_____________________________________ Block 1 __________________________________________#\nmodel_13.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same',input_shape=(224,224,3)))\nmodel_13.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_13.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 2 __________________________________________#\nmodel_13.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_13.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_13.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n#_____________________________________ Block 3 __________________________________________#\nmodel_13.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 4 __________________________________________#\nmodel_13.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 5 __________________________________________#\nmodel_13.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_13.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n\n\nmodel_13.add(tf.keras.layers.Flatten())\n\n#______________________________Dense Layers_______________________________________________#\nmodel_13.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_13.add(tf.keras.layers.Dropout(.5))\n\nmodel_13.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_13.add(tf.keras.layers.Dropout(.5))\n\n#______________________________Output Layer _______________________________________________#\nmodel_13.add(tf.keras.layers.Dense(units=6,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:04:26.890614Z","iopub.execute_input":"2021-11-01T15:04:26.890884Z","iopub.status.idle":"2021-11-01T15:04:27.031783Z","shell.execute_reply.started":"2021-11-01T15:04:26.890850Z","shell.execute_reply":"2021-11-01T15:04:27.031153Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_13.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:04:27.033076Z","iopub.execute_input":"2021-11-01T15:04:27.033409Z","iopub.status.idle":"2021-11-01T15:04:27.049388Z","shell.execute_reply.started":"2021-11-01T15:04:27.033372Z","shell.execute_reply":"2021-11-01T15:04:27.047937Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_13.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory=model_13.fit(train_generator,validation_data=validation_generator, epochs=20,verbose=1)\nmodel_13.save('model_13.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:04:27.050556Z","iopub.execute_input":"2021-11-01T15:04:27.050803Z","iopub.status.idle":"2021-11-01T16:06:48.233474Z","shell.execute_reply.started":"2021-11-01T15:04:27.050770Z","shell.execute_reply":"2021-11-01T16:06:48.232606Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_16=tf.keras.models.Sequential()\n\n#_____________________________________ Block 1 __________________________________________#\nmodel_16.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same',input_shape=(224,224,3)))\nmodel_16.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_16.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 2 __________________________________________#\nmodel_16.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_16.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_16.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n#_____________________________________ Block 3 __________________________________________#\nmodel_16.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 4 __________________________________________#\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 5 __________________________________________#\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_16.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n\n\nmodel_16.add(tf.keras.layers.Flatten())\n\n#______________________________Dense Layers_______________________________________________#\nmodel_16.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_16.add(tf.keras.layers.Dropout(.5))\n\nmodel_16.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_16.add(tf.keras.layers.Dropout(.5))\n\n#______________________________Output Layer _______________________________________________#\nmodel_16.add(tf.keras.layers.Dense(units=6,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T16:06:48.240218Z","iopub.execute_input":"2021-11-01T16:06:48.242465Z","iopub.status.idle":"2021-11-01T16:06:48.464651Z","shell.execute_reply.started":"2021-11-01T16:06:48.242420Z","shell.execute_reply":"2021-11-01T16:06:48.463875Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model_16.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T16:06:48.465769Z","iopub.execute_input":"2021-11-01T16:06:48.466019Z","iopub.status.idle":"2021-11-01T16:06:49.017221Z","shell.execute_reply.started":"2021-11-01T16:06:48.465985Z","shell.execute_reply":"2021-11-01T16:06:49.016532Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_16.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory_16=model_16.fit(train_generator,validation_data=validation_generator, epochs=20,verbose=1)\nmodel_16.save('model_16.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T16:06:49.018566Z","iopub.execute_input":"2021-11-01T16:06:49.018912Z","iopub.status.idle":"2021-11-01T17:11:58.665047Z","shell.execute_reply.started":"2021-11-01T16:06:49.018875Z","shell.execute_reply":"2021-11-01T17:11:58.664205Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_19=tf.keras.models.Sequential()\n\n#_____________________________________ Block 1 __________________________________________#\nmodel_19.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same',input_shape=(224,224,3)))\nmodel_19.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_19.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 2 __________________________________________#\nmodel_19.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_19.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding=\"same\"))\nmodel_19.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n#_____________________________________ Block 3 __________________________________________#\nmodel_19.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu',padding='same'))\n\nmodel_19.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 4 __________________________________________#\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\n\nmodel_19.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n\n#_____________________________________ Block 5 __________________________________________#\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\nmodel_19.add(tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu',padding='same'))\n\nmodel_19.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n \n\n\nmodel_19.add(tf.keras.layers.Flatten())\n\n#______________________________Dense Layers_______________________________________________#\nmodel_19.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_19.add(tf.keras.layers.Dropout(.5))\n\nmodel_19.add(tf.keras.layers.Dense(units=4096,activation='relu'))\nmodel_19.add(tf.keras.layers.Dropout(.5))\n\n#______________________________Output Layer _______________________________________________#\nmodel_19.add(tf.keras.layers.Dense(units=6,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:54:35.069477Z","iopub.execute_input":"2021-11-01T18:54:35.069994Z","iopub.status.idle":"2021-11-01T18:54:35.247598Z","shell.execute_reply.started":"2021-11-01T18:54:35.069956Z","shell.execute_reply":"2021-11-01T18:54:35.246904Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model_19.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:54:35.774775Z","iopub.execute_input":"2021-11-01T18:54:35.774999Z","iopub.status.idle":"2021-11-01T18:54:35.789523Z","shell.execute_reply.started":"2021-11-01T18:54:35.774972Z","shell.execute_reply":"2021-11-01T18:54:35.788800Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model_19.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory_19=model_19.fit(train_generator,validation_data=validation_generator, epochs=20,verbose=1)\nmodel_19.save('model_19.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:54:48.598207Z","iopub.execute_input":"2021-11-01T18:54:48.598504Z","iopub.status.idle":"2021-11-01T20:04:41.137969Z","shell.execute_reply.started":"2021-11-01T18:54:48.598475Z","shell.execute_reply":"2021-11-01T20:04:41.137201Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"predict_11 = model_11.predict(test_generator,batch_size=20,verbose=1)\npredict_13 = model_13.predict(test_generator,batch_size=20,verbose=1)\npredict_16 = model_16.predict(test_generator,batch_size=20,verbose=1)\npredict_19 = model_19.predict(test_generator,batch_size=20,verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\n\nacc_11=history_11.history['accuracy']\nval_acc_11=history_11.history['val_accuracy']\nloss_11=history_11.history['loss']\nval_loss_11=history_11.history['val_loss']\n\nacc_13=history.history['accuracy']\nval_acc_13=history.history['val_accuracy']\nloss_13=history.history['loss']\nval_loss_13=history.history['val_loss']\n\nacc_16=history_16.history['accuracy']\nval_acc_16=history_16.history['val_accuracy']\nloss_16=history_16.history['loss']\nval_loss_16=history_16.history['val_loss']\n\nacc_19=history_19.history['accuracy']\nval_acc_19=history_19.history['val_accuracy']\nloss_19=history_19.history['loss']\nval_loss_19=history_19.history['val_loss']\n\nepochs=range(len(acc_11)) # Get number of epochs\n\nacc=[acc_11, acc_13, acc_16, acc_19]\nval_acc=[val_acc_11, val_acc_13, val_acc_16, val_acc_19]\nloss=[loss_11,loss_13,loss_16,loss_19]\nval_loss=[val_loss_11, val_loss_13, val_loss_16,val_loss_19]\n\n\ndef plot_model(modelnumber,name_model):\n    plt.plot(epochs, acc[modelnumber], 'r')\n    plt.plot(epochs, val_acc[modelnumber], 'b')\n    plt.title(f'{name_model} Training and validation accuracy')\n    plt.xlabel('epochs')\n    plt.ylabel('accuracy')\n    plt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n    plt.show()\n\n\n    #------------------------------------------------\n    # Plot training and validation loss per epoch\n    #------------------------------------------------\n    plt.plot(epochs, loss[modelnumber], 'r')\n    plt.plot(epochs, val_loss[modelnumber], 'b')\n    plt.title(f'{name_model} Training and validation loss')\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend([\"Training Loss\",\"Validation Loss\"])\n    plt.show()\n\n\ndef plot_4_models(model,title):\n    plt.plot(epochs, model[0], 'r')\n    plt.plot(epochs, model[1], 'b')\n    plt.plot(epochs, model[2], 'g')\n    plt.plot(epochs, model[2], 'y')\n    plt.title(f'Training {title} for 4 model')\n    plt.xlabel('epochs')\n    plt.ylabel(title)\n    plt.legend([\"vgg_11\",\"vgg_13\",\"vgg_16\",\"vgg_19\"])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:29:51.821368Z","iopub.execute_input":"2021-11-01T20:29:51.821626Z","iopub.status.idle":"2021-11-01T20:29:51.844929Z","shell.execute_reply.started":"2021-11-01T20:29:51.821598Z","shell.execute_reply":"2021-11-01T20:29:51.844204Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"plot_model(0,'vgg_11')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:18:11.637883Z","iopub.execute_input":"2021-11-01T20:18:11.638657Z","iopub.status.idle":"2021-11-01T20:18:12.071389Z","shell.execute_reply.started":"2021-11-01T20:18:11.638603Z","shell.execute_reply":"2021-11-01T20:18:12.070689Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plot_model(1,'vgg_13')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:18:51.399694Z","iopub.execute_input":"2021-11-01T20:18:51.399958Z","iopub.status.idle":"2021-11-01T20:18:51.810773Z","shell.execute_reply.started":"2021-11-01T20:18:51.399926Z","shell.execute_reply":"2021-11-01T20:18:51.810014Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"plot_model(2,'vgg_16')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:19:33.218041Z","iopub.execute_input":"2021-11-01T20:19:33.218615Z","iopub.status.idle":"2021-11-01T20:19:33.642857Z","shell.execute_reply.started":"2021-11-01T20:19:33.218575Z","shell.execute_reply":"2021-11-01T20:19:33.642190Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"plot_model(3,'vgg_19')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:20:42.569695Z","iopub.execute_input":"2021-11-01T20:20:42.570341Z","iopub.status.idle":"2021-11-01T20:20:42.984824Z","shell.execute_reply.started":"2021-11-01T20:20:42.570290Z","shell.execute_reply":"2021-11-01T20:20:42.984174Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"plot_4_models(acc,'accuracy')\nplot_4_models(val_acc,'validation accuracy')\nplot_4_models(loss,'loss')\nplot_4_models(val_loss,'validation loss')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:30:12.069096Z","iopub.execute_input":"2021-11-01T20:30:12.069648Z","iopub.status.idle":"2021-11-01T20:30:28.888205Z","shell.execute_reply.started":"2021-11-01T20:30:12.069610Z","shell.execute_reply":"2021-11-01T20:30:28.887517Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}